# Model Configuration for Enterprise Marketing AI Agents
# This file contains configuration for all AI models used in the system

# OpenAI Models
openai:
  # Chat/Completion Models (Optimized for Cost)
  gpt-4o-mini:
    temperature: 0.6
    max_tokens: 2048
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    use_case: "Most cost-effective option for development"

  gpt-3.5-turbo:
    temperature: 0.6
    max_tokens: 2048
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    use_case: "Balanced cost and performance"

  gpt-4-turbo:
    temperature: 0.7
    max_tokens: 4096
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    use_case: "Higher quality (keep for optional upgrades)"

  gpt-4:
    temperature: 0.7
    max_tokens: 8192
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    use_case: "Legacy, most expensive"

  # Embedding Models
  text-embedding-3-small:
    dimension: 1536
    batch_size: 100
    encoding_format: float
    max_tokens: 8191
    use_case: "General purpose, cost-effective"

  text-embedding-3-large:
    dimension: 3072
    batch_size: 100
    encoding_format: float
    max_tokens: 8191
    use_case: "Higher quality, more expensive"

  text-embedding-ada-002:
    dimension: 1536
    batch_size: 100
    encoding_format: float
    max_tokens: 8191
    use_case: "Legacy model"

# Anthropic Models (if using Claude)
anthropic:
  claude-3-opus:
    temperature: 0.7
    max_tokens: 4096

  claude-3-sonnet:
    temperature: 0.7
    max_tokens: 4096

  claude-3-haiku:
    temperature: 0.7
    max_tokens: 4096

# Default Model Settings (Optimized for Development/Cost)
defaults:
  chat_model: "gpt-4o-mini"  # Most cost-effective option
  embedding_model: "text-embedding-3-small"  # Already cost-optimized
  temperature: 0.6  # Slightly lower for consistency
  max_retries: 3
  timeout: 60
  # Note: gpt-4o-mini is ~15-60x cheaper than GPT-4 models
